{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/migue/data-science/portfolio/text-summarizer'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_ckpt: str\n",
    "    num_train_epochs: int\n",
    "    warmup_steps: int\n",
    "    per_device_train_batch_size: int\n",
    "    per_device_eval_batch_size: int\n",
    "    weight_decay: float\n",
    "    logging_steps: int\n",
    "    evaluation_strategy: str\n",
    "    eval_steps: int\n",
    "    save_steps: float\n",
    "    gradient_accumulation_steps: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textSummarizer.constants import *\n",
    "from textSummarizer.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self):\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            model_ckpt=config.model_ckpt,\n",
    "            num_train_epochs=params.num_train_epochs,\n",
    "            warmup_steps=params.warmup_steps,\n",
    "            per_device_train_batch_size=params.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=params.per_device_eval_batch_size,\n",
    "            weight_decay=params.weight_decay,\n",
    "            logging_steps=params.logging_steps,\n",
    "            evaluation_strategy=params.evaluation_strategy,\n",
    "            eval_steps=params.eval_steps,\n",
    "            save_steps=params.save_steps,\n",
    "            gradient_accumulation_steps=params.gradient_accumulation_steps,\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-02 19:02:09,975: INFO: config: PyTorch version 2.3.1 available.]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.model_ckpt)\n",
    "        model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            self.config.model_ckpt\n",
    "        ).to(device)\n",
    "        seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)\n",
    "\n",
    "        dataset_pt = load_from_disk(self.config.data_path)\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            output_dir=self.config.root_dir,\n",
    "            num_train_epochs=self.config.num_train_epochs,\n",
    "            warmup_steps=self.config.warmup_steps,\n",
    "            per_device_train_batch_size=self.config.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=self.config.per_device_eval_batch_size,\n",
    "            weight_decay=self.config.weight_decay,\n",
    "            logging_steps=self.config.logging_steps,\n",
    "            evaluation_strategy=self.config.evaluation_strategy,\n",
    "            eval_steps=self.config.eval_steps,\n",
    "            save_steps=self.config.save_steps,\n",
    "            gradient_accumulation_steps=self.config.gradient_accumulation_steps,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model_pegasus,\n",
    "            args=args,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=seq2seq_data_collator,\n",
    "            train_dataset=dataset_pt[\"train\"],\n",
    "            eval_dataset=dataset_pt[\"validation\"],\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        model_pegasus.save_pretrained(\n",
    "            os.path.join(self.config.root_dir, \"pegasus-samsum-model\")\n",
    "        )\n",
    "        tokenizer.save_pretrained(\n",
    "            os.path.join(self.config.root_dir, \"pegasus-samsum-model\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-02 19:02:10,108: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-09-02 19:02:10,109: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-02 19:02:10,110: INFO: common: created a directory at: artifacts]\n",
      "[2024-09-02 19:02:10,110: INFO: common: created a directory at: artifacts/model_trainer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/migue/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/migue/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eff244cd9ff4381bcec0e1ee4c3336b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0899, 'grad_norm': 11.069536209106445, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 2.9334, 'grad_norm': 25.39984130859375, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.02}\n",
      "{'loss': 3.1411, 'grad_norm': 12.329587936401367, 'learning_rate': 3e-06, 'epoch': 0.02}\n",
      "{'loss': 3.0877, 'grad_norm': 12.36679744720459, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 3.08, 'grad_norm': 10.263320922851562, 'learning_rate': 5e-06, 'epoch': 0.04}\n",
      "{'loss': 2.7008, 'grad_norm': 37.445091247558594, 'learning_rate': 6e-06, 'epoch': 0.05}\n",
      "{'loss': 2.8397, 'grad_norm': 34.78185272216797, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 2.6756, 'grad_norm': 7.89933967590332, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 2.365, 'grad_norm': 13.456506729125977, 'learning_rate': 9e-06, 'epoch': 0.07}\n",
      "{'loss': 2.3218, 'grad_norm': 11.648741722106934, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 2.3053, 'grad_norm': 6.698170185089111, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.09}\n",
      "{'loss': 2.1811, 'grad_norm': 8.34107494354248, 'learning_rate': 1.2e-05, 'epoch': 0.1}\n",
      "{'loss': 2.4273, 'grad_norm': 14.906949996948242, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.11}\n",
      "{'loss': 2.0836, 'grad_norm': 19.247480392456055, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9964, 'grad_norm': 6.482517242431641, 'learning_rate': 1.5e-05, 'epoch': 0.12}\n",
      "{'loss': 2.1477, 'grad_norm': 6.855518817901611, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.13}\n",
      "{'loss': 2.1003, 'grad_norm': 5.758449077606201, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.14}\n",
      "{'loss': 1.976, 'grad_norm': 5.804727554321289, 'learning_rate': 1.8e-05, 'epoch': 0.15}\n",
      "{'loss': 2.008, 'grad_norm': 21.50102424621582, 'learning_rate': 1.9e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9601, 'grad_norm': 5.297266960144043, 'learning_rate': 2e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9496, 'grad_norm': 15.672050476074219, 'learning_rate': 2.1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9822, 'grad_norm': 9.176446914672852, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8337, 'grad_norm': 3.521362781524658, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9411, 'grad_norm': 7.045313358306885, 'learning_rate': 2.4e-05, 'epoch': 0.2}\n",
      "{'loss': 1.7902, 'grad_norm': 38.554744720458984, 'learning_rate': 2.5e-05, 'epoch': 0.2}\n",
      "{'loss': 1.7986, 'grad_norm': 4.517706871032715, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8369, 'grad_norm': 6.430121898651123, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.22}\n",
      "{'loss': 1.7826, 'grad_norm': 5.477557182312012, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7475, 'grad_norm': 3.933863401412964, 'learning_rate': 2.9e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7969, 'grad_norm': 4.069471836090088, 'learning_rate': 3e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8182, 'grad_norm': 8.360623359680176, 'learning_rate': 3.1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7389, 'grad_norm': 9.2689847946167, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7562, 'grad_norm': 3.898055076599121, 'learning_rate': 3.3e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8065, 'grad_norm': 4.395298004150391, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7722, 'grad_norm': 4.823721408843994, 'learning_rate': 3.5e-05, 'epoch': 0.29}\n",
      "{'loss': 1.684, 'grad_norm': 4.7972588539123535, 'learning_rate': 3.6e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7316, 'grad_norm': 4.518595218658447, 'learning_rate': 3.7e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8883, 'grad_norm': 5.363234996795654, 'learning_rate': 3.8e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7346, 'grad_norm': 3.544482469558716, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6949, 'grad_norm': 3.5611414909362793, 'learning_rate': 4e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8106, 'grad_norm': 5.586697101593018, 'learning_rate': 4.1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.834, 'grad_norm': 4.5347394943237305, 'learning_rate': 4.2e-05, 'epoch': 0.34}\n",
      "{'loss': 1.7966, 'grad_norm': 4.424197673797607, 'learning_rate': 4.3e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7951, 'grad_norm': 5.149111270904541, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7382, 'grad_norm': 3.735720634460449, 'learning_rate': 4.5e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7306, 'grad_norm': 4.359231948852539, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.37}\n",
      "{'loss': 1.6896, 'grad_norm': 4.920977592468262, 'learning_rate': 4.7e-05, 'epoch': 0.38}\n",
      "{'loss': 1.6838, 'grad_norm': 3.714599370956421, 'learning_rate': 4.8e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7025, 'grad_norm': 4.760226249694824, 'learning_rate': 4.9e-05, 'epoch': 0.4}\n",
      "{'loss': 1.6446, 'grad_norm': 4.936435222625732, 'learning_rate': 5e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956d568a1a1249d287e47de7b59fb628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5456265211105347, 'eval_runtime': 11.1103, 'eval_samples_per_second': 73.625, 'eval_steps_per_second': 18.451, 'epoch': 0.41}\n",
      "{'loss': 1.7593, 'grad_norm': 3.390408992767334, 'learning_rate': 4.931224209078404e-05, 'epoch': 0.42}\n",
      "{'loss': 1.6637, 'grad_norm': 6.170805931091309, 'learning_rate': 4.862448418156809e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7241, 'grad_norm': 6.4096269607543945, 'learning_rate': 4.793672627235214e-05, 'epoch': 0.43}\n",
      "{'loss': 1.6482, 'grad_norm': 5.202908039093018, 'learning_rate': 4.724896836313618e-05, 'epoch': 0.44}\n",
      "{'loss': 1.7453, 'grad_norm': 4.602560043334961, 'learning_rate': 4.6561210453920225e-05, 'epoch': 0.45}\n",
      "{'loss': 1.6246, 'grad_norm': 4.560962677001953, 'learning_rate': 4.5873452544704265e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7239, 'grad_norm': 7.0066070556640625, 'learning_rate': 4.518569463548831e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7155, 'grad_norm': 5.484926223754883, 'learning_rate': 4.449793672627235e-05, 'epoch': 0.47}\n",
      "{'loss': 1.6879, 'grad_norm': 13.360481262207031, 'learning_rate': 4.38101788170564e-05, 'epoch': 0.48}\n",
      "{'loss': 1.6434, 'grad_norm': 4.858806610107422, 'learning_rate': 4.312242090784045e-05, 'epoch': 0.49}\n",
      "{'loss': 1.6718, 'grad_norm': 4.889963150024414, 'learning_rate': 4.243466299862449e-05, 'epoch': 0.5}\n",
      "{'loss': 1.6775, 'grad_norm': 3.543501853942871, 'learning_rate': 4.174690508940853e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7935, 'grad_norm': 3.8360822200775146, 'learning_rate': 4.1059147180192575e-05, 'epoch': 0.51}\n",
      "{'loss': 1.6737, 'grad_norm': 4.9308366775512695, 'learning_rate': 4.0371389270976615e-05, 'epoch': 0.52}\n",
      "{'loss': 1.6464, 'grad_norm': 6.303647994995117, 'learning_rate': 3.968363136176066e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7106, 'grad_norm': 17.047609329223633, 'learning_rate': 3.899587345254471e-05, 'epoch': 0.54}\n",
      "{'loss': 1.6372, 'grad_norm': 4.265300273895264, 'learning_rate': 3.830811554332875e-05, 'epoch': 0.55}\n",
      "{'loss': 1.701, 'grad_norm': 4.194301128387451, 'learning_rate': 3.76203576341128e-05, 'epoch': 0.55}\n",
      "{'loss': 1.6405, 'grad_norm': 4.232572078704834, 'learning_rate': 3.693259972489684e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7395, 'grad_norm': 3.4103550910949707, 'learning_rate': 3.624484181568088e-05, 'epoch': 0.57}\n",
      "{'loss': 1.6568, 'grad_norm': 5.01718807220459, 'learning_rate': 3.5557083906464925e-05, 'epoch': 0.58}\n",
      "{'loss': 1.5937, 'grad_norm': 5.941340923309326, 'learning_rate': 3.486932599724897e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7543, 'grad_norm': 3.209639072418213, 'learning_rate': 3.418156808803301e-05, 'epoch': 0.59}\n",
      "{'loss': 1.6659, 'grad_norm': 7.589540004730225, 'learning_rate': 3.349381017881706e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7808, 'grad_norm': 4.009336471557617, 'learning_rate': 3.28060522696011e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7077, 'grad_norm': 6.813330173492432, 'learning_rate': 3.211829436038515e-05, 'epoch': 0.62}\n",
      "{'loss': 1.6663, 'grad_norm': 3.373657464981079, 'learning_rate': 3.143053645116919e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5987, 'grad_norm': 3.632728099822998, 'learning_rate': 3.0742778541953235e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5988, 'grad_norm': 4.578745365142822, 'learning_rate': 3.005502063273728e-05, 'epoch': 0.64}\n",
      "{'loss': 1.7187, 'grad_norm': 5.959710597991943, 'learning_rate': 2.9367262723521322e-05, 'epoch': 0.65}\n",
      "{'loss': 1.6072, 'grad_norm': 3.380685806274414, 'learning_rate': 2.8679504814305362e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7542, 'grad_norm': 3.9223546981811523, 'learning_rate': 2.799174690508941e-05, 'epoch': 0.67}\n",
      "{'loss': 1.5433, 'grad_norm': 3.499638795852661, 'learning_rate': 2.7303988995873453e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7031, 'grad_norm': 4.818436145782471, 'learning_rate': 2.66162310866575e-05, 'epoch': 0.68}\n",
      "{'loss': 1.6391, 'grad_norm': 4.432999134063721, 'learning_rate': 2.592847317744154e-05, 'epoch': 0.69}\n",
      "{'loss': 1.6191, 'grad_norm': 3.972388982772827, 'learning_rate': 2.5240715268225585e-05, 'epoch': 0.7}\n",
      "{'loss': 1.5464, 'grad_norm': 3.8451836109161377, 'learning_rate': 2.455295735900963e-05, 'epoch': 0.71}\n",
      "{'loss': 1.5908, 'grad_norm': 3.440570592880249, 'learning_rate': 2.3865199449793672e-05, 'epoch': 0.72}\n",
      "{'loss': 1.636, 'grad_norm': 6.298971176147461, 'learning_rate': 2.317744154057772e-05, 'epoch': 0.72}\n",
      "{'loss': 1.5795, 'grad_norm': 3.5718538761138916, 'learning_rate': 2.248968363136176e-05, 'epoch': 0.73}\n",
      "{'loss': 1.6699, 'grad_norm': 4.51021146774292, 'learning_rate': 2.1801925722145804e-05, 'epoch': 0.74}\n",
      "{'loss': 1.5645, 'grad_norm': 5.114506244659424, 'learning_rate': 2.111416781292985e-05, 'epoch': 0.75}\n",
      "{'loss': 1.6633, 'grad_norm': 3.366173505783081, 'learning_rate': 2.0426409903713894e-05, 'epoch': 0.76}\n",
      "{'loss': 1.6125, 'grad_norm': 3.746429443359375, 'learning_rate': 1.9738651994497935e-05, 'epoch': 0.77}\n",
      "{'loss': 1.6044, 'grad_norm': 7.035218715667725, 'learning_rate': 1.9050894085281982e-05, 'epoch': 0.77}\n",
      "{'loss': 1.6236, 'grad_norm': 3.7843258380889893, 'learning_rate': 1.8363136176066026e-05, 'epoch': 0.78}\n",
      "{'loss': 1.5721, 'grad_norm': 3.3666727542877197, 'learning_rate': 1.767537826685007e-05, 'epoch': 0.79}\n",
      "{'loss': 1.6448, 'grad_norm': 6.681150436401367, 'learning_rate': 1.6987620357634113e-05, 'epoch': 0.8}\n",
      "{'loss': 1.7692, 'grad_norm': 5.781829833984375, 'learning_rate': 1.6299862448418157e-05, 'epoch': 0.81}\n",
      "{'loss': 1.5473, 'grad_norm': 4.2152934074401855, 'learning_rate': 1.56121045392022e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c74398f7b645d481e8f4bf84c88902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4777475595474243, 'eval_runtime': 11.2453, 'eval_samples_per_second': 72.741, 'eval_steps_per_second': 18.23, 'epoch': 0.81}\n",
      "{'loss': 1.5978, 'grad_norm': 7.776360511779785, 'learning_rate': 1.4924346629986246e-05, 'epoch': 0.82}\n",
      "{'loss': 1.5762, 'grad_norm': 19.00647735595703, 'learning_rate': 1.4236588720770288e-05, 'epoch': 0.83}\n",
      "{'loss': 1.6485, 'grad_norm': 3.2901852130889893, 'learning_rate': 1.3548830811554334e-05, 'epoch': 0.84}\n",
      "{'loss': 1.6079, 'grad_norm': 4.7837958335876465, 'learning_rate': 1.2861072902338378e-05, 'epoch': 0.85}\n",
      "{'loss': 1.5617, 'grad_norm': 4.614064693450928, 'learning_rate': 1.2173314993122421e-05, 'epoch': 0.86}\n",
      "{'loss': 1.6639, 'grad_norm': 5.476214408874512, 'learning_rate': 1.1485557083906467e-05, 'epoch': 0.86}\n",
      "{'loss': 1.6019, 'grad_norm': 4.263691425323486, 'learning_rate': 1.0797799174690509e-05, 'epoch': 0.87}\n",
      "{'loss': 1.5935, 'grad_norm': 3.207488775253296, 'learning_rate': 1.0110041265474554e-05, 'epoch': 0.88}\n",
      "{'loss': 1.568, 'grad_norm': 7.215763568878174, 'learning_rate': 9.422283356258598e-06, 'epoch': 0.89}\n",
      "{'loss': 1.7132, 'grad_norm': 4.139143943786621, 'learning_rate': 8.73452544704264e-06, 'epoch': 0.9}\n",
      "{'loss': 1.6435, 'grad_norm': 3.297262191772461, 'learning_rate': 8.046767537826686e-06, 'epoch': 0.9}\n",
      "{'loss': 1.6075, 'grad_norm': 3.8931078910827637, 'learning_rate': 7.3590096286107285e-06, 'epoch': 0.91}\n",
      "{'loss': 1.5741, 'grad_norm': 3.4857754707336426, 'learning_rate': 6.671251719394773e-06, 'epoch': 0.92}\n",
      "{'loss': 1.6279, 'grad_norm': 4.137194633483887, 'learning_rate': 5.983493810178818e-06, 'epoch': 0.93}\n",
      "{'loss': 1.653, 'grad_norm': 8.731199264526367, 'learning_rate': 5.2957359009628615e-06, 'epoch': 0.94}\n",
      "{'loss': 1.5878, 'grad_norm': 4.947547912597656, 'learning_rate': 4.607977991746905e-06, 'epoch': 0.94}\n",
      "{'loss': 1.5692, 'grad_norm': 9.65069580078125, 'learning_rate': 3.92022008253095e-06, 'epoch': 0.95}\n",
      "{'loss': 1.5631, 'grad_norm': 4.280778408050537, 'learning_rate': 3.2324621733149936e-06, 'epoch': 0.96}\n",
      "{'loss': 1.5341, 'grad_norm': 3.81585693359375, 'learning_rate': 2.5447042640990374e-06, 'epoch': 0.97}\n",
      "{'loss': 1.6315, 'grad_norm': 9.587690353393555, 'learning_rate': 1.8569463548830814e-06, 'epoch': 0.98}\n",
      "{'loss': 1.5399, 'grad_norm': 4.585268497467041, 'learning_rate': 1.1691884456671253e-06, 'epoch': 0.99}\n",
      "{'loss': 1.6003, 'grad_norm': 7.958619594573975, 'learning_rate': 4.814305364511692e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 716.1513, 'train_samples_per_second': 20.571, 'train_steps_per_second': 1.713, 'train_loss': 1.8124701065461424, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer_config.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
